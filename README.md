# Chest Cancer Classification using MLflow & DVC 🫁 🔬

## 🎯 Project Overview

An end-to-end deep learning pipeline for classifying chest cancer types (Adenocarcinoma vs Normal) using state-of-the-art deep learning techniques. The project achieves 84% accuracy and implements MLOps best practices using MLflow and DVC.

### 🎯 Objective
- Predict **Adenocarcinoma cancer** vs **Normal cancer** in breast using machine learning.

### 🚀 Achievements
- **84% Accuracy** on classifying 1000+ chest images 🖼️.
- **20+ Model Iterations** tracked with **MLflow** for seamless experiment management. 📈
- **20% Performance Boost** achieved with refined deep learning techniques. 🌟
- Streamlined **Data Preparation** workflows using **DVC** for scalable operations. ⚙️
- Reduced manual intervention by **40%** through automated training workflows. 🤖

## 🛠️ Tech Stack

- **ML/DL Framework:** TensorFlow, Keras
- **Experiment Tracking:** MLflow
- **Data Version Control:** DVC
- **Cloud Platforms:** AWS
- **Containerization:** Docker
- **Programming:** Python 3.8+

## 📊 Model Performance

| Metric      | Value  |
|-------------|--------|
| **Accuracy**  | 84%    |
| **F1 Score**  | 0.83   |
| **Precision** | 0.85   |
| **Recall**    | 0.82   |

---
## 🛠️ Tasks Followed  

1. **Introduction & GitHub Repository Setup**  
   - Organized the repository structure for better maintainability.  
   - Set up version control with Git and DVC for data tracking.  

2. **Project Template Creation**  
   - Designed a modular and scalable template for the entire project.  
   - Ensured separation of concerns for ease of collaboration.  

3. **Project Setup & Requirements Installation**  
   - Defined dependencies in `requirements.txt`.  
   - Installed necessary libraries and tools for ML development.  

4. **Logging, Utils & Exception Module**  
   - Implemented robust logging mechanisms for debugging.  
   - Created utility functions and a custom exception module for error handling.  

5. **Project Workflows**  
   - Defined workflows for data preprocessing, training, and prediction pipelines.  
   - Streamlined the flow to enhance efficiency and modularity.  

6. **All Components Notebook Experiment**  
   - Conducted experiments in Jupyter notebooks to validate each pipeline component.  
   - Performed exploratory data analysis (EDA) and initial modeling.  

7. **All Components Modular Code Implementation**  
   - Transformed notebook experiments into reusable and maintainable Python modules.  
   - Ensured modularity for scalability and ease of updates.  

8. **Training Pipeline**  
   - Built a training pipeline to automate data ingestion, preprocessing, and model training.  
   - Logged model metrics and parameters for tracking improvements.  

9. **MLflow (MLOps Tool)**  
   - Integrated MLflow for **experiment tracking** and **model registration**.  
   - Tracked metrics for 20+ model iterations to optimize performance.  

10. **DVC (MLOps Tool)**  
    - Utilized DVC for pipeline tracking and data version control.  
    - Enabled reproducible workflows for preprocessing and training stages.  

11. **Prediction Pipeline & User App Creation**  
    - Developed a prediction pipeline for real-time inference.  
    - Created a **Flask API** and **Streamlit app** for user-friendly interaction.  

12. **Docker**  
    - Containerized the entire application for consistent deployment across environments.  
    - Ensured portability and scalability using Docker.  

13. **Final CI/CD Deployment on AWS and Azure**  
    - Automated the deployment process using CI/CD pipelines.  
    - Deployed the application on **AWS** and **Azure** for high availability and performance.  

---

## 🔄 MLOps Pipeline

### 📦 **Data Version Control (DVC)**
- Efficient handling of **1000+ medical images** 🖼️.
- Reproducible **data preprocessing workflows** 🔁.
- Achieved a **40% reduction** in data preparation time ⏱️.

### 📈 **Experiment Tracking (MLflow)**
- **Automated logging** of 20+ model iterations. 📝
- **Hyperparameter optimization tracking** for improved model performance. ⚙️
- **Model performance metrics visualization** for easy comparison. 📊

### 🔧 **CI/CD Integration**
- **Automated testing** with **GitHub Actions** ✅.
- Continuous **model retraining pipeline** to maintain accuracy 🚀.
- **Automated cloud deployment** for real-time predictions 🌐.

---

## 🚀 Future Enhancements  

1. Incorporate advanced hyperparameter optimization techniques.  
2. Expand datasets for improved generalization and robustness.  
3. Deploy the model using **AWS Lambda** or **Azure Functions** for serverless architecture.  
4. Add real-time monitoring of model performance using **Prometheus** or similar tools.  
5. Integrate explainability tools like **SHAP** to understand model predictions.  